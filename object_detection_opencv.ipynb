{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection_opencv.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmrz2Mrl0SxXh8c+fDCbP/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhsingh1411/yolo_v3_objecct_detection/blob/main/object_detection_opencv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqiATxuvA4tv"
      },
      "source": [
        "importing intial lib "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eh5IOGG9uwF"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image,ImageDraw,ImageFont\n",
        "\n",
        "from IPython.display import display\n",
        "from seaborn import color_palette\n",
        "\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfzq32XxBIEm"
      },
      "source": [
        "Model hyper parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-xmHaAvA1cg"
      },
      "source": [
        "_BATCH_NORM_DECAY=0.9\n",
        "_BATCH_NORM_EPSILON=1e-05\n",
        "_LEAKY_RELU=0.1\n",
        "_ANCHORS=[(10, 13), (16, 30), (33, 23),\n",
        "            (30, 61), (62, 45), (59, 119),\n",
        "            (116, 90), (156, 198), (373, 326)]\n",
        "\n",
        "_MODEL_SIZE=(416,416)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPHk0gKIFHZ5"
      },
      "source": [
        "## Batch norm and fixed padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reBrDUYDEv8C"
      },
      "source": [
        "def batch_norm(inputs,training,data_format):\n",
        "\n",
        "\n",
        "  '''performs batch normalization using as standrad set of parameters'''\n",
        "\n",
        "  return tf.layers.batch_normalization(\n",
        "        inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
        "        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
        "        scale=True, training=training)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzFFoAoFExHP"
      },
      "source": [
        "def fixed_padding(inputs,kernel_size,data_format):\n",
        "\n",
        "  pad_total=kernel_size-1\n",
        "  pad_beg=pad_total//2\n",
        "  pad_end=pad_total-pad_beg\n",
        "\n",
        "\n",
        "  if data_format=='channels_first':\n",
        "\n",
        "    padded_inputs=tf.pad(inputs,[[0, 0], [0, 0],\n",
        "                                        [pad_beg, pad_end],\n",
        "                                        [pad_beg, pad_end]])\n",
        "    \n",
        "  else :\n",
        "    padded_inputs=tf.pad(inputs,[[0, 0], [pad_beg, pad_end],\n",
        "                                        [pad_beg, pad_end], [0, 0]])\n",
        "    \n",
        "  return padded_inputs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2JVBdTiExPG"
      },
      "source": [
        "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
        "    \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n",
        "    if strides > 1:\n",
        "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
        "\n",
        "    return tf.layers.conv2d(\n",
        "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
        "        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n",
        "        use_bias=False, data_format=data_format)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykZE57VtExR7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pPiEOKpExW2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYkhAZgQExcL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Lk68gYExaZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgTGzfC_ExVO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}